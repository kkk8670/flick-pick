# -*- coding: utf-8 -*-
"""rating_processing (csv).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AEVp6vQn8pY2IMmO2u4wQySrcRxmnu52
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

from pyspark import SparkContext, SparkConf
from pyspark.sql import *
from pyspark.sql.functions import *
from pyspark.sql.types import *
spark = SparkSession.builder.master("local").appName("Processing").getOrCreate()
inputFilePath = "/content/drive/MyDrive/BigData/32m/ratings.csv"
df = ( spark.read.option("header", "true").option("inferSchema", "true").csv(inputFilePath) )
df.printSchema()
df.show()

#检查是否有缺失值
import pandas as pd
dfP = pd.read_csv(inputFilePath)
print("Check for missing values：")
print(dfP.isnull().sum())

#去除时间戳列
df = df.drop("timestamp")
df.show()

#确保每列的格式正确
df = df.withColumn("userId", col("userId").cast("int")) \
       .withColumn("movieId", col("movieId").cast("int")) \
       .withColumn("rating", col("rating").cast("double"))

df.printSchema()

#检查是否有重复行
if df.count() == df.dropDuplicates().count():
    print("没有重复的行")
else:
    print("有重复的行")

#缓存数据并存入csv文件
df.cache()
outputFilePath = "/content/drive/MyDrive/5003-BigData/data/32m"
df.coalesce(1).write.option("header", "false").csv(outputFilePath)